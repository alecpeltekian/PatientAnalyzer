{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Processing PDF: Patient_30627.pdf\n",
      "DEBUG: About to extract task performance...\n",
      "DEBUG: Extracting TASK PERFORMANCE values...\n",
      "DEBUG: Found TASK PERFORMANCE section\n",
      "       TASK PERFORMANCE\n",
      "Feature\n",
      "Value\n",
      "Button Press Accuracy (%)\n",
      "75.0\n",
      "False Alarms (%)\n",
      "0.6\n",
      "Median Reaction Time (ms)\n",
      "576.0\n",
      "...\n",
      "DEBUG: Found Button Press Accuracy: 75.0\n",
      "DEBUG: Found False Alarms: 0.6\n",
      "DEBUG: Found Median Reaction Time: 576.0\n",
      "DEBUG: Task values: {'Button Press Accuracy': 75.0, 'False Alarms': 0.6, 'Median Reaction Time': 576.0}\n",
      "DEBUG: About to extract ERP features...\n",
      "DEBUG: Extracting ERP FEATURES values...\n",
      "DEBUG: Found ERP FEATURES section\n",
      "       ERP FEATURES\n",
      "Feature\n",
      "Stimulus\n",
      "Amplitude (Î¼V)\n",
      "Latency (ms)\n",
      "Avg Amplitude (Î¼V)\n",
      "P50\n",
      "Standard\n",
      "-0.13\n",
      "50.3\n",
      "-1.05\n",
      "N100\n",
      "Standard\n",
      "-5.81\n",
      "102.7\n",
      "-4.05\n",
      "P200\n",
      "Standard\n",
      "2.82\n",
      "202.3\n",
      "1.74\n",
      "N200\n",
      "Target\n",
      "-2.06\n",
      "272.0\n",
      "0.61\n",
      "P3b\n",
      "Target\n",
      "5.31\n",
      "442.0\n",
      "2.92\n",
      "SW\n",
      "Target\n",
      "0.70\n",
      "588.6\n",
      "2.17\n",
      "P3a\n",
      "Distractor\n",
      "3.64\n",
      "390.9\n",
      "1.12\n",
      "...\n",
      "DEBUG: ERP values: None\n",
      "DEBUG: About to extract EEG features...\n",
      "DEBUG: Extracting EEG FEATURES values...\n",
      "DEBUG: Found EEG FEATURES section\n",
      "       EEG FEATURES\n",
      "Feature\n",
      "Peak Frequency\n",
      "Power\n",
      "Peak Alpha\n",
      "10.25\n",
      "239.9\n",
      "...\n",
      "DEBUG: Found Peak Alpha Frequency: 10.25\n",
      "DEBUG: EEG values: {'Peak Alpha Frequency': 10.25}\n",
      "DEBUG: Found Button Press Accuracy interpretation: Low\n",
      "DEBUG: Found Median Reaction Time interpretation: Delayed\n",
      "DEBUG: Found P50 Amplitude interpretation: Normal\n",
      "DEBUG: Found P3b Amplitude interpretation: Normal\n",
      "DEBUG: Found P3b Latency interpretation: Delayed\n",
      "DEBUG: Found Peak Alpha Frequency interpretation: Normal\n",
      "\n",
      "================================================================================\n",
      "                         MEDICAL REPORT EXTRACTION RESULTS\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ STUDY FINDINGS:\n",
      "--------------------------------------------------\n",
      "This is an abnormal study due to delayed median reaction time and P3b latency and low button press accuracy. Collectively, study \n",
      "findings suggest reduced stimulus processing (including evaluation and classification speed) as well as reduced attentional \n",
      "resources and executive function. These findings suggest increase risk of cognitive dysfunction and premorbid dementia. Clinical \n",
      "correlation is suggested.\n",
      "\n",
      "ðŸ’­ STUDY DISCUSSION:\n",
      "--------------------------------------------------\n",
      "Button Press Accuracy: Low\n",
      "Median Reaction Time: Delayed\n",
      "P50 Amplitude: Normal\n",
      "P3b Amplitude: Normal\n",
      "P3b Latency: Delayed\n",
      "Peak Alpha Frequency: Normal\n",
      "\n",
      "ðŸ“Š EXTRACTED VALUES:\n",
      "--------------------------------------------------\n",
      "\n",
      "  Task Performance:\n",
      "    â€¢ Button Press Accuracy    : 75.0\n",
      "    â€¢ False Alarms             : 0.6\n",
      "    â€¢ Median Reaction Time     : 576.0\n",
      "\n",
      "  EEG Features:\n",
      "    â€¢ Peak Alpha Frequency     : 10.25\n",
      "\n",
      "ðŸ” CLINICAL INTERPRETATIONS:\n",
      "--------------------------------------------------\n",
      "  ðŸ”´ Button Press Accuracy    : Low\n",
      "  ðŸ”´ Median Reaction Time     : Delayed\n",
      "  ðŸŸ¢ P50 Amplitude            : Normal\n",
      "  ðŸŸ¢ P3b Amplitude            : Normal\n",
      "  ðŸ”´ P3b Latency              : Delayed\n",
      "  ðŸŸ¢ Peak Alpha Frequency     : Normal\n",
      "\n",
      "ðŸ§® CALCULATED INTERPRETATIONS (Based on Normal Ranges):\n",
      "--------------------------------------------------\n",
      "  ðŸ”´ Button Press Accuracy    : Low\n",
      "  ðŸŸ¢ False Alarms             : Normal\n",
      "  ðŸ”´ Median Reaction Time     : Delayed\n",
      "  ðŸŸ¢ Peak Alpha Frequency     : Normal\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ðŸ’¾ Summary saved to 'medical_report_summary.csv'\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import fitz  # PyMuPDF\n",
    "import json\n",
    "\n",
    "class RobustMedicalExtractor:\n",
    "    \"\"\"\n",
    "    Robust extractor that properly parses tabular medical data\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.debug_mode = True\n",
    "        \n",
    "        # Normal ranges based on your reference data\n",
    "        self.normal_ranges = {\n",
    "            'Button Press Accuracy': {'min': 90, 'max': 100, 'unit': '%'},\n",
    "            'False Alarms': {'min': 0, 'max': 5, 'unit': '%'},\n",
    "            'Median Reaction Time': {'min': 400, 'max': 500, 'unit': 'ms'},\n",
    "            'P50 Amplitude': {'min': 2.5, 'max': 3.0, 'unit': 'Î¼V'},\n",
    "            'P3b Amplitude': {'min': 5.5, 'max': 6.5, 'unit': 'Î¼V'},\n",
    "            'P3b Latency': {'min': 380, 'max': 420, 'unit': 'ms'},\n",
    "            'Peak Alpha Frequency': {'min': 8.0, 'max': 12.0, 'unit': 'Hz'}\n",
    "        }\n",
    "    \n",
    "    def debug_print(self, message: str, data: any = None):\n",
    "        \"\"\"Print debug information\"\"\"\n",
    "        if self.debug_mode:\n",
    "            print(f\"DEBUG: {message}\")\n",
    "            if data is not None:\n",
    "                print(f\"       {data}\")\n",
    "    \n",
    "    def extract_text_pymupdf(self, pdf_path: str) -> str:\n",
    "        \"\"\"Extract text using PyMuPDF with better formatting preservation\"\"\"\n",
    "        try:\n",
    "            doc = fitz.open(pdf_path)\n",
    "            text = \"\"\n",
    "            \n",
    "            for page_num in range(len(doc)):\n",
    "                page = doc.load_page(page_num)\n",
    "                # Use different extraction method to preserve table structure\n",
    "                page_text = page.get_text(\"text\")\n",
    "                text += f\"\\n=== PAGE {page_num + 1} ===\\n{page_text}\\n\"\n",
    "            \n",
    "            doc.close()\n",
    "            return text\n",
    "        except Exception as e:\n",
    "            self.debug_print(f\"PyMuPDF extraction failed: {e}\")\n",
    "            return \"\"\n",
    "    \n",
    "    def extract_task_performance_table(self, text: str) -> Dict:\n",
    "        \"\"\"Extract values from TASK PERFORMANCE table\"\"\"\n",
    "        self.debug_print(\"Extracting TASK PERFORMANCE values...\")\n",
    "        \n",
    "        values = {}\n",
    "        \n",
    "        # Look for the TASK PERFORMANCE section\n",
    "        task_section_pattern = r'TASK PERFORMANCE.*?(?=ERP FEATURES|EEG FEATURES|$)'\n",
    "        task_match = re.search(task_section_pattern, text, re.DOTALL | re.IGNORECASE)\n",
    "        \n",
    "        if task_match:\n",
    "            task_section = task_match.group(0)\n",
    "            self.debug_print(\"Found TASK PERFORMANCE section\", task_section[:200] + \"...\")\n",
    "            \n",
    "            # Extract Button Press Accuracy - look for percentage value\n",
    "            accuracy_patterns = [\n",
    "                r'Button Press Accuracy[^\\d]*(\\d+\\.?\\d*)',\n",
    "                r'Accuracy[^\\d]*(\\d+\\.?\\d*)',\n",
    "                r'Button.*?Accuracy.*?(\\d+\\.?\\d*)'\n",
    "            ]\n",
    "            \n",
    "            for pattern in accuracy_patterns:\n",
    "                match = re.search(pattern, task_section, re.IGNORECASE)\n",
    "                if match:\n",
    "                    values['Button Press Accuracy'] = float(match.group(1))\n",
    "                    self.debug_print(f\"Found Button Press Accuracy: {match.group(1)}\")\n",
    "                    break\n",
    "            \n",
    "            # Extract False Alarms\n",
    "            false_alarm_patterns = [\n",
    "                r'False Alarms[^\\d]*(\\d+\\.?\\d*)',\n",
    "                r'False.*?Alarms.*?(\\d+\\.?\\d*)'\n",
    "            ]\n",
    "            \n",
    "            for pattern in false_alarm_patterns:\n",
    "                match = re.search(pattern, task_section, re.IGNORECASE)\n",
    "                if match:\n",
    "                    values['False Alarms'] = float(match.group(1))\n",
    "                    self.debug_print(f\"Found False Alarms: {match.group(1)}\")\n",
    "                    break\n",
    "            \n",
    "            # Extract Median Reaction Time - look for larger numbers (reaction times are usually 400-800ms)\n",
    "            reaction_patterns = [\n",
    "                r'Median Reaction Time[^\\d]*(\\d{3,4}\\.?\\d*)',  # 3-4 digits for reaction time\n",
    "                r'Reaction Time[^\\d]*(\\d{3,4}\\.?\\d*)',\n",
    "                r'Reaction.*?Time.*?(\\d{3,4}\\.?\\d*)'\n",
    "            ]\n",
    "            \n",
    "            for pattern in reaction_patterns:\n",
    "                match = re.search(pattern, task_section, re.IGNORECASE)\n",
    "                if match:\n",
    "                    values['Median Reaction Time'] = float(match.group(1))\n",
    "                    self.debug_print(f\"Found Median Reaction Time: {match.group(1)}\")\n",
    "                    break\n",
    "        \n",
    "        else:\n",
    "            self.debug_print(\"TASK PERFORMANCE section not found\")\n",
    "        \n",
    "        return values\n",
    "    \n",
    "    def extract_erp_table(self, text: str) -> Dict:\n",
    "        \"\"\"Extract values from ERP FEATURES table\"\"\"\n",
    "        self.debug_print(\"Extracting ERP FEATURES values...\")\n",
    "        \n",
    "        try:\n",
    "            values = {}\n",
    "            \n",
    "            # Look for ERP FEATURES section\n",
    "            erp_section_pattern = r'ERP FEATURES.*?(?=EEG FEATURES|Test Name|$)'\n",
    "            self.debug_print(f\"ERP regex pattern: {erp_section_pattern}\")\n",
    "            \n",
    "            erp_match = re.search(erp_section_pattern, text, re.DOTALL | re.IGNORECASE)\n",
    "            self.debug_print(f\"ERP match found: {erp_match is not None}\")\n",
    "            \n",
    "            if erp_match:\n",
    "                erp_section = erp_match.group(0)\n",
    "                self.debug_print(\"Found ERP FEATURES section\", erp_section[:300] + \"...\")\n",
    "                \n",
    "                # Show the exact lines for debugging\n",
    "                lines = erp_section.split('\\n')\n",
    "                self.debug_print(\"ERP section lines:\")\n",
    "                for i, line in enumerate(lines):\n",
    "                    self.debug_print(f\"  Line {i}: '{line}'\")\n",
    "                \n",
    "                # Extract P50 amplitude - more flexible pattern for table format\n",
    "                self.debug_print(\"Trying P50 extraction...\")\n",
    "                \n",
    "                # Simple line-by-line approach first\n",
    "                for line_num, line in enumerate(lines):\n",
    "                    self.debug_print(f\"Checking line {line_num}: '{line}'\")\n",
    "                    if 'P50' in line and 'Standard' in line:\n",
    "                        self.debug_print(f\"Found P50 Standard line: '{line}'\")\n",
    "                        # Extract numbers from the line\n",
    "                        numbers = re.findall(r'([+-]?\\d+\\.?\\d*)', line)\n",
    "                        self.debug_print(f\"Numbers found: {numbers}\")\n",
    "                        if numbers:\n",
    "                            values['P50 Amplitude'] = float(numbers[0])\n",
    "                            self.debug_print(f\"Found P50 Amplitude (line method): {numbers[0]}\")\n",
    "                            break\n",
    "                \n",
    "                # Extract P3b amplitude and latency\n",
    "                self.debug_print(\"Trying P3b extraction...\")\n",
    "                for line_num, line in enumerate(lines):\n",
    "                    self.debug_print(f\"Checking P3b line {line_num}: '{line}'\")\n",
    "                    if 'P3b' in line and 'Target' in line:\n",
    "                        self.debug_print(f\"Found P3b Target line: '{line}'\")\n",
    "                        # Extract numbers from the line\n",
    "                        numbers = re.findall(r'([+-]?\\d+\\.?\\d*)', line)\n",
    "                        self.debug_print(f\"Numbers found: {numbers}\")\n",
    "                        if len(numbers) >= 2:\n",
    "                            values['P3b Amplitude'] = float(numbers[0])\n",
    "                            values['P3b Latency'] = float(numbers[1])\n",
    "                            self.debug_print(f\"Found P3b Amplitude (line method): {numbers[0]}\")\n",
    "                            self.debug_print(f\"Found P3b Latency (line method): {numbers[1]}\")\n",
    "                            break\n",
    "            else:\n",
    "                self.debug_print(\"ERP FEATURES section not found\")\n",
    "            \n",
    "            self.debug_print(f\"ERP extraction completed. Found values: {values}\")\n",
    "            return values\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.debug_print(f\"ERROR in ERP extraction: {e}\")\n",
    "            import traceback\n",
    "            self.debug_print(f\"Traceback: {traceback.format_exc()}\")\n",
    "            return {}\n",
    "    \n",
    "    def extract_eeg_table(self, text: str) -> Dict:\n",
    "        \"\"\"Extract values from EEG FEATURES table\"\"\"\n",
    "        self.debug_print(\"Extracting EEG FEATURES values...\")\n",
    "        \n",
    "        values = {}\n",
    "        \n",
    "        # Look for EEG FEATURES section\n",
    "        eeg_section_pattern = r'EEG FEATURES.*?(?=EEG POWER SPECTRUM|Test Name|$)'\n",
    "        eeg_match = re.search(eeg_section_pattern, text, re.DOTALL | re.IGNORECASE)\n",
    "        \n",
    "        if eeg_match:\n",
    "            eeg_section = eeg_match.group(0)\n",
    "            self.debug_print(\"Found EEG FEATURES section\", eeg_section[:200] + \"...\")\n",
    "            \n",
    "            # Extract Peak Alpha Frequency - look for Peak Alpha row\n",
    "            # Pattern: Peak Alpha [frequency] [power]\n",
    "            alpha_pattern = r'Peak Alpha\\s+(\\d+\\.?\\d*)'\n",
    "            alpha_match = re.search(alpha_pattern, eeg_section, re.IGNORECASE)\n",
    "            if alpha_match:\n",
    "                values['Peak Alpha Frequency'] = float(alpha_match.group(1))\n",
    "                self.debug_print(f\"Found Peak Alpha Frequency: {alpha_match.group(1)}\")\n",
    "        else:\n",
    "            self.debug_print(\"EEG FEATURES section not found\")\n",
    "        \n",
    "        return values\n",
    "    \n",
    "    def extract_erp_table(self, text: str) -> Dict:\n",
    "        \"\"\"Extract values from ERP FEATURES table\"\"\"\n",
    "        self.debug_print(\"Extracting ERP FEATURES values...\")\n",
    "        \n",
    "        values = {}\n",
    "        \n",
    "        # Look for ERP FEATURES section\n",
    "        erp_section_pattern = r'ERP FEATURES.*?(?=EEG FEATURES|Test Name|$)'\n",
    "        erp_match = re.search(erp_section_pattern, text, re.DOTALL | re.IGNORECASE)\n",
    "        \n",
    "        if erp_match:\n",
    "            erp_section = erp_match.group(0)\n",
    "            self.debug_print(\"Found ERP FEATURES section\", erp_section[:300] + \"...\")\n",
    "            \n",
    "    \n",
    "    def extract_study_sections(self, text: str) -> Dict:\n",
    "        \"\"\"Extract Study Findings and Study Discussion sections\"\"\"\n",
    "        sections = {}\n",
    "        \n",
    "        # Extract Study Findings\n",
    "        findings_pattern = r'Study Findings?:?\\s*(.*?)(?=Study Discussion|$)'\n",
    "        findings_match = re.search(findings_pattern, text, re.DOTALL | re.IGNORECASE)\n",
    "        if findings_match:\n",
    "            sections['study_findings'] = findings_match.group(1).strip()\n",
    "        \n",
    "        # Extract Study Discussion\n",
    "        discussion_pattern = r'Study Discussion:?\\s*(.*?)(?=Study Protocol|Test Name|Physician|$)'\n",
    "        discussion_match = re.search(discussion_pattern, text, re.DOTALL | re.IGNORECASE)\n",
    "        if discussion_match:\n",
    "            sections['study_discussion'] = discussion_match.group(1).strip()\n",
    "        \n",
    "        return sections\n",
    "    \n",
    "    def extract_discussion_interpretations(self, discussion_text: str) -> Dict:\n",
    "        \"\"\"Extract interpretations from Study Discussion section\"\"\"\n",
    "        interpretations = {}\n",
    "        \n",
    "        patterns = {\n",
    "            'Button Press Accuracy': r'Button Press Accuracy[:\\s]*(Low|Normal|High)',\n",
    "            'Median Reaction Time': r'Median Reaction Time[:\\s]*(Delayed|Normal|Fast)',\n",
    "            'P50 Amplitude': r'P50 Amplitude[:\\s]*(Low|Normal|High)',\n",
    "            'P3b Amplitude': r'P3b Amplitude[:\\s]*(Low|Normal|High)',\n",
    "            'P3b Latency': r'P3b Latency[:\\s]*(Delayed|Normal|Fast)',\n",
    "            'Peak Alpha Frequency': r'Peak Alpha Frequency[:\\s]*(Low|Normal|High)'\n",
    "        }\n",
    "        \n",
    "        for metric, pattern in patterns.items():\n",
    "            match = re.search(pattern, discussion_text, re.IGNORECASE)\n",
    "            if match:\n",
    "                interpretations[metric] = match.group(1)\n",
    "                self.debug_print(f\"Found {metric} interpretation: {match.group(1)}\")\n",
    "        \n",
    "        return interpretations\n",
    "    \n",
    "    def interpret_values(self, values: Dict) -> Dict:\n",
    "        \"\"\"Calculate interpretations based on normal ranges\"\"\"\n",
    "        interpretations = {}\n",
    "        \n",
    "        for metric, value in values.items():\n",
    "            if metric in self.normal_ranges:\n",
    "                range_info = self.normal_ranges[metric]\n",
    "                min_val = range_info['min']\n",
    "                max_val = range_info['max']\n",
    "                \n",
    "                if metric in ['Median Reaction Time', 'P3b Latency']:\n",
    "                    # For timing metrics, higher values are \"Delayed\"\n",
    "                    if value > max_val:\n",
    "                        interpretations[metric] = 'Delayed'\n",
    "                    elif value < min_val:\n",
    "                        interpretations[metric] = 'Fast'\n",
    "                    else:\n",
    "                        interpretations[metric] = 'Normal'\n",
    "                else:\n",
    "                    # For other metrics, use Low/Normal/High\n",
    "                    if value < min_val:\n",
    "                        interpretations[metric] = 'Low'\n",
    "                    elif value > max_val:\n",
    "                        interpretations[metric] = 'High'\n",
    "                    else:\n",
    "                        interpretations[metric] = 'Normal'\n",
    "        \n",
    "        return interpretations\n",
    "    \n",
    "    def process_pdf(self, pdf_path: str) -> Dict:\n",
    "        \"\"\"Main processing function\"\"\"\n",
    "        self.debug_print(f\"Processing PDF: {pdf_path}\")\n",
    "        \n",
    "        # Extract text\n",
    "        text = self.extract_text_pymupdf(pdf_path)\n",
    "        if not text:\n",
    "            return {\"error\": \"Could not extract text from PDF\"}\n",
    "        \n",
    "        # Extract sections\n",
    "        sections = self.extract_study_sections(text)\n",
    "        \n",
    "        # Extract values from tables\n",
    "        self.debug_print(\"About to extract task performance...\")\n",
    "        task_values = self.extract_task_performance_table(text)\n",
    "        self.debug_print(f\"Task values: {task_values}\")\n",
    "        \n",
    "        self.debug_print(\"About to extract ERP features...\")\n",
    "        erp_values = self.extract_erp_table(text)\n",
    "        self.debug_print(f\"ERP values: {erp_values}\")\n",
    "        \n",
    "        self.debug_print(\"About to extract EEG features...\")\n",
    "        eeg_values = self.extract_eeg_table(text)\n",
    "        self.debug_print(f\"EEG values: {eeg_values}\")\n",
    "        \n",
    "        # Combine all values - ensure all are dictionaries\n",
    "        all_values = {}\n",
    "        if task_values:\n",
    "            all_values.update(task_values)\n",
    "        if erp_values:\n",
    "            all_values.update(erp_values)\n",
    "        if eeg_values:\n",
    "            all_values.update(eeg_values)\n",
    "        \n",
    "        # Get interpretations\n",
    "        discussion_interpretations = {}\n",
    "        if 'study_discussion' in sections:\n",
    "            discussion_interpretations = self.extract_discussion_interpretations(sections['study_discussion'])\n",
    "        \n",
    "        calculated_interpretations = self.interpret_values(all_values)\n",
    "        \n",
    "        return {\n",
    "            'study_findings': sections.get('study_findings', ''),\n",
    "            'study_discussion': sections.get('study_discussion', ''),\n",
    "            'extracted_values': all_values,\n",
    "            'discussion_interpretations': discussion_interpretations,\n",
    "            'calculated_interpretations': calculated_interpretations,\n",
    "            'full_text': text\n",
    "        }\n",
    "\n",
    "# Clean output function\n",
    "def print_clean_results(results: Dict):\n",
    "    \"\"\"Print results in a clean, organized format\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"                         MEDICAL REPORT EXTRACTION RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Study Findings\n",
    "    if results.get('study_findings'):\n",
    "        print(\"\\nðŸ“‹ STUDY FINDINGS:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(results['study_findings'])\n",
    "    \n",
    "    # Study Discussion  \n",
    "    if results.get('study_discussion'):\n",
    "        print(\"\\nðŸ’­ STUDY DISCUSSION:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(results['study_discussion'])\n",
    "    \n",
    "    # Extracted Values\n",
    "    extracted_values = results.get('extracted_values', {})\n",
    "    if extracted_values:\n",
    "        print(\"\\nðŸ“Š EXTRACTED VALUES:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Group by category\n",
    "        task_metrics = ['Button Press Accuracy', 'False Alarms', 'Median Reaction Time']\n",
    "        erp_metrics = ['P50 Amplitude', 'P3b Amplitude', 'P3b Latency'] \n",
    "        eeg_metrics = ['Peak Alpha Frequency']\n",
    "        \n",
    "        def print_category(title, metrics, values):\n",
    "            category_values = {k: v for k, v in values.items() if k in metrics}\n",
    "            if category_values:\n",
    "                print(f\"\\n  {title}:\")\n",
    "                for metric, value in category_values.items():\n",
    "                    print(f\"    â€¢ {metric:<25}: {value}\")\n",
    "        \n",
    "        print_category(\"Task Performance\", task_metrics, extracted_values)\n",
    "        print_category(\"ERP Features\", erp_metrics, extracted_values)\n",
    "        print_category(\"EEG Features\", eeg_metrics, extracted_values)\n",
    "    \n",
    "    # Discussion Interpretations\n",
    "    discussion_interp = results.get('discussion_interpretations', {})\n",
    "    if discussion_interp:\n",
    "        print(\"\\nðŸ” CLINICAL INTERPRETATIONS:\")\n",
    "        print(\"-\" * 50)\n",
    "        for metric, interpretation in discussion_interp.items():\n",
    "            status_emoji = \"ðŸ”´\" if interpretation.lower() in ['low', 'delayed'] else \"ðŸŸ¢\" if interpretation.lower() == 'normal' else \"ðŸŸ¡\"\n",
    "            print(f\"  {status_emoji} {metric:<25}: {interpretation}\")\n",
    "    \n",
    "    # Calculated Interpretations\n",
    "    calc_interp = results.get('calculated_interpretations', {})\n",
    "    if calc_interp:\n",
    "        print(\"\\nðŸ§® CALCULATED INTERPRETATIONS (Based on Normal Ranges):\")\n",
    "        print(\"-\" * 50)\n",
    "        for metric, interpretation in calc_interp.items():\n",
    "            status_emoji = \"ðŸ”´\" if interpretation.lower() in ['low', 'delayed'] else \"ðŸŸ¢\" if interpretation.lower() == 'normal' else \"ðŸŸ¡\"\n",
    "            print(f\"  {status_emoji} {metric:<25}: {interpretation}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Usage example with clean output\n",
    "def main():\n",
    "    extractor = RobustMedicalExtractor()\n",
    "    extractor.debug_mode = True  # Turn ON debug to see what's happening\n",
    "    \n",
    "    # Process PDF\n",
    "    pdf_path = \"Patient_30627.pdf\"  # Replace with your PDF path\n",
    "    \n",
    "    try:\n",
    "        results = extractor.process_pdf(pdf_path)\n",
    "        \n",
    "        # Print clean results\n",
    "        print_clean_results(results)\n",
    "        \n",
    "        # Create summary DataFrame\n",
    "        summary_data = []\n",
    "        extracted_values = results.get('extracted_values', {})\n",
    "        discussion_interp = results.get('discussion_interpretations', {})\n",
    "        calc_interp = results.get('calculated_interpretations', {})\n",
    "        \n",
    "        all_metrics = set(extracted_values.keys()) | set(discussion_interp.keys()) | set(calc_interp.keys())\n",
    "        \n",
    "        for metric in sorted(all_metrics):\n",
    "            summary_data.append({\n",
    "                'Metric': metric,\n",
    "                'Value': extracted_values.get(metric, 'Not found'),\n",
    "                'Clinical_Interpretation': discussion_interp.get(metric, 'Not found'),\n",
    "                'Calculated_Interpretation': calc_interp.get(metric, 'Not found')\n",
    "            })\n",
    "        \n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        \n",
    "        # Save to CSV\n",
    "        summary_df.to_csv('medical_report_summary.csv', index=False)\n",
    "        print(f\"\\nðŸ’¾ Summary saved to 'medical_report_summary.csv'\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error processing PDF: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¬ Medical PDF Extractor - Simplified Version\n",
      "============================================================\n",
      "Processing: Patient_30627.pdf\n",
      "\n",
      "================================================================================\n",
      "                    MEDICAL REPORT ANALYSIS RESULTS\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ GENERATED STUDY FINDINGS (Based on Data Analysis):\n",
      "------------------------------------------------------------\n",
      "This is an abnormal study due to low button press accuracy, delayed median reaction time, low p50 amplitude, low p3b amplitude, and delayed p3b latency. Collectively, study findings suggest reduced stimulus processing (including evaluation and classification speed), and reduced attentional resources and executive function, and altered sensory gating and filtering. These findings suggest increased risk of cognitive dysfunction and may warrant clinical correlation.\n",
      "\n",
      "ðŸ’­ GENERATED STUDY DISCUSSION (Based on Data Analysis):\n",
      "------------------------------------------------------------\n",
      "Button Press Accuracy: Low\n",
      "Median Reaction Time: Delayed\n",
      "P50 Amplitude: Low\n",
      "P3b Amplitude: Low\n",
      "P3b Latency: Delayed\n",
      "Peak Alpha Frequency: Normal\n",
      "False Alarms: Normal\n",
      "\n",
      "Detailed Analysis:\n",
      "Decreased button press accuracy reflects subjects' reduced ability to pay attention to test stimuli, directly correlated with executive function deficits.\n",
      "Prolonged reaction time reflects slower cognitive processing and may indicate executive dysfunction.\n",
      "Decreased P50 amplitude may reflect impaired sensory gating and pre-attentive processing.\n",
      "Decreased P3b amplitude reflects reduced attentional resources allocated to target stimulus processing.\n",
      "Delayed P3b latency indicates slower stimulus evaluation and classification processes, often associated with cognitive slowing.\n",
      "\n",
      "ðŸ“Š EXTRACTED VALUES:\n",
      "--------------------------------------------------\n",
      "\n",
      "  Task Performance:\n",
      "    ðŸ”´ Button Press Accuracy    : 75.0 (Low)\n",
      "    ðŸŸ¢ False Alarms             : 0.6 (Normal)\n",
      "    ðŸ”´ Median Reaction Time     : 576.0 (Delayed)\n",
      "\n",
      "  ERP Features:\n",
      "    ðŸ”´ P50 Amplitude            : -0.13 (Low)\n",
      "    ðŸ”´ P3b Amplitude            : 5.31 (Low)\n",
      "    ðŸ”´ P3b Latency              : 442.0 (Delayed)\n",
      "\n",
      "  EEG Features:\n",
      "    ðŸŸ¢ Peak Alpha Frequency     : 10.25 (Normal)\n",
      "\n",
      "ðŸ§® OUR INTERPRETATIONS (Based on Normal Ranges):\n",
      "-------------------------------------------------------\n",
      "  ðŸ”´ Button Press Accuracy    : Low\n",
      "  ðŸŸ¢ False Alarms             : Normal\n",
      "  ðŸ”´ Median Reaction Time     : Delayed\n",
      "  ðŸ”´ P50 Amplitude            : Low\n",
      "  ðŸ”´ P3b Amplitude            : Low\n",
      "  ðŸ”´ P3b Latency              : Delayed\n",
      "  ðŸŸ¢ Peak Alpha Frequency     : Normal\n",
      "\n",
      "ðŸ“„ ORIGINAL REPORT INTERPRETATIONS (For Comparison):\n",
      "-------------------------------------------------------\n",
      "  ðŸ”´ Button Press Accuracy    : Low\n",
      "  ðŸ”´ Median Reaction Time     : Delayed\n",
      "  ðŸŸ¢ P50 Amplitude            : Normal\n",
      "  ðŸŸ¢ P3b Amplitude            : Normal\n",
      "  ðŸ”´ P3b Latency              : Delayed\n",
      "  ðŸŸ¢ Peak Alpha Frequency     : Normal\n",
      "\n",
      "================================================================================\n",
      "ðŸ’¾ Results saved to medical_report_analysis.csv\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "\n",
    "class SimpleMedicalExtractor:\n",
    "    \"\"\"\n",
    "    Simplified medical report extractor that actually works!\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Normal ranges for interpretation\n",
    "        self.normal_ranges = {\n",
    "            'Button Press Accuracy': {'min': 90, 'max': 100},\n",
    "            'False Alarms': {'min': 0, 'max': 5},\n",
    "            'Median Reaction Time': {'min': 400, 'max': 500},\n",
    "            'P50 Amplitude': {'min': 2.5, 'max': 3.0},\n",
    "            'P3b Amplitude': {'min': 5.5, 'max': 6.5},\n",
    "            'P3b Latency': {'min': 380, 'max': 420},\n",
    "            'Peak Alpha Frequency': {'min': 8.0, 'max': 12.0}\n",
    "        }\n",
    "    \n",
    "    def extract_pdf_text(self, pdf_path: str) -> str:\n",
    "        \"\"\"Extract text from PDF\"\"\"\n",
    "        try:\n",
    "            doc = fitz.open(pdf_path)\n",
    "            text = \"\"\n",
    "            for page in doc:\n",
    "                text += page.get_text() + \"\\n\"\n",
    "            doc.close()\n",
    "            return text\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading PDF: {e}\")\n",
    "            return \"\"\n",
    "    \n",
    "    def generate_study_findings(self, values: Dict, interpretations: Dict) -> str:\n",
    "        \"\"\"Generate Study Findings based on extracted values and interpretations\"\"\"\n",
    "        \n",
    "        # Count abnormal findings\n",
    "        abnormal_findings = []\n",
    "        abnormal_count = 0\n",
    "        \n",
    "        for metric, interpretation in interpretations.items():\n",
    "            if interpretation.lower() in ['low', 'delayed', 'high']:\n",
    "                abnormal_findings.append(f\"{interpretation.lower()} {metric.lower()}\")\n",
    "                abnormal_count += 1\n",
    "        \n",
    "        # Generate findings text\n",
    "        if abnormal_count == 0:\n",
    "            findings = \"This is a normal study with all measured parameters within expected ranges.\"\n",
    "        else:\n",
    "            if abnormal_count == 1:\n",
    "                findings = f\"This is an abnormal study due to {abnormal_findings[0]}.\"\n",
    "            elif abnormal_count == 2:\n",
    "                findings = f\"This is an abnormal study due to {abnormal_findings[0]} and {abnormal_findings[1]}.\"\n",
    "            else:\n",
    "                findings = f\"This is an abnormal study due to {', '.join(abnormal_findings[:-1])}, and {abnormal_findings[-1]}.\"\n",
    "            \n",
    "            # Add clinical implications based on specific findings\n",
    "            implications = []\n",
    "            \n",
    "            # Check for cognitive/attention issues\n",
    "            cognitive_issues = any(metric in ['Button Press Accuracy', 'Median Reaction Time', 'P3b Latency'] \n",
    "                                 and interpretation.lower() in ['low', 'delayed'] \n",
    "                                 for metric, interpretation in interpretations.items())\n",
    "            \n",
    "            if cognitive_issues:\n",
    "                implications.append(\"reduced stimulus processing (including evaluation and classification speed)\")\n",
    "                implications.append(\"reduced attentional resources and executive function\")\n",
    "            \n",
    "            # Check for sensory processing issues\n",
    "            sensory_issues = any(metric in ['P50 Amplitude'] \n",
    "                               and interpretation.lower() in ['low', 'high'] \n",
    "                               for metric, interpretation in interpretations.items())\n",
    "            \n",
    "            if sensory_issues:\n",
    "                implications.append(\"altered sensory gating and filtering\")\n",
    "            \n",
    "            # Check for alpha rhythm issues\n",
    "            alpha_issues = any(metric in ['Peak Alpha Frequency'] \n",
    "                             and interpretation.lower() in ['low', 'high'] \n",
    "                             for metric, interpretation in interpretations.items())\n",
    "            \n",
    "            if alpha_issues:\n",
    "                implications.append(\"altered cortical arousal and attention networks\")\n",
    "            \n",
    "            if implications:\n",
    "                findings += f\" Collectively, study findings suggest {', and '.join(implications)}.\"\n",
    "                \n",
    "                # Add risk assessment\n",
    "                if cognitive_issues:\n",
    "                    findings += \" These findings suggest increased risk of cognitive dysfunction and may warrant clinical correlation.\"\n",
    "        \n",
    "        return findings\n",
    "    \n",
    "    def generate_study_discussion(self, values: Dict, interpretations: Dict) -> str:\n",
    "        \"\"\"Generate Study Discussion based on extracted values and interpretations\"\"\"\n",
    "        \n",
    "        discussion_lines = []\n",
    "        \n",
    "        # Add each metric with its interpretation\n",
    "        metric_order = [\n",
    "            'Button Press Accuracy',\n",
    "            'Median Reaction Time', \n",
    "            'P50 Amplitude',\n",
    "            'P3b Amplitude',\n",
    "            'P3b Latency',\n",
    "            'Peak Alpha Frequency'\n",
    "        ]\n",
    "        \n",
    "        for metric in metric_order:\n",
    "            if metric in interpretations:\n",
    "                interpretation = interpretations[metric]\n",
    "                discussion_lines.append(f\"{metric}: {interpretation}\")\n",
    "        \n",
    "        # Add any additional metrics not in the ordered list\n",
    "        for metric, interpretation in interpretations.items():\n",
    "            if metric not in metric_order:\n",
    "                discussion_lines.append(f\"{metric}: {interpretation}\")\n",
    "        \n",
    "        # Add detailed explanations for abnormal findings\n",
    "        explanations = []\n",
    "        \n",
    "        for metric, interpretation in interpretations.items():\n",
    "            if interpretation.lower() == 'low':\n",
    "                if metric == 'Button Press Accuracy':\n",
    "                    explanations.append(\"Decreased button press accuracy reflects subjects' reduced ability to pay attention to test stimuli, directly correlated with executive function deficits.\")\n",
    "                elif metric == 'P50 Amplitude':\n",
    "                    explanations.append(\"Decreased P50 amplitude may reflect impaired sensory gating and pre-attentive processing.\")\n",
    "                elif metric == 'P3b Amplitude':\n",
    "                    explanations.append(\"Decreased P3b amplitude reflects reduced attentional resources allocated to target stimulus processing.\")\n",
    "            \n",
    "            elif interpretation.lower() == 'delayed':\n",
    "                if metric == 'Median Reaction Time':\n",
    "                    explanations.append(\"Prolonged reaction time reflects slower cognitive processing and may indicate executive dysfunction.\")\n",
    "                elif metric == 'P3b Latency':\n",
    "                    explanations.append(\"Delayed P3b latency indicates slower stimulus evaluation and classification processes, often associated with cognitive slowing.\")\n",
    "            \n",
    "            elif interpretation.lower() == 'high':\n",
    "                if metric == 'Peak Alpha Frequency':\n",
    "                    explanations.append(\"Elevated alpha frequency may reflect heightened cortical arousal or compensatory mechanisms.\")\n",
    "                elif metric == 'P50 Amplitude':\n",
    "                    explanations.append(\"Increased P50 amplitude may indicate sensory hypersensitivity or reduced inhibitory control.\")\n",
    "        \n",
    "        # Combine discussion and explanations\n",
    "        discussion = '\\n'.join(discussion_lines)\n",
    "        if explanations:\n",
    "            discussion += '\\n\\nDetailed Analysis:\\n' + '\\n'.join(explanations)\n",
    "        \n",
    "        return discussion\n",
    "    \n",
    "    def extract_all_values(self, text: str) -> Dict:\n",
    "        \"\"\"Extract all medical values using the working line-by-line approach\"\"\"\n",
    "        \n",
    "        values = {}\n",
    "        lines = [line.strip() for line in text.split('\\n')]\n",
    "        \n",
    "        # Extract Task Performance values\n",
    "        for i, line in enumerate(lines):\n",
    "            # Button Press Accuracy - look for the pattern\n",
    "            if 'Button Press Accuracy' in line and i+1 < len(lines):\n",
    "                try:\n",
    "                    # Next line should have the value\n",
    "                    value = float(lines[i+1])\n",
    "                    values['Button Press Accuracy'] = value\n",
    "                except ValueError:\n",
    "                    pass\n",
    "            \n",
    "            # False Alarms\n",
    "            if 'False Alarms' in line and i+1 < len(lines):\n",
    "                try:\n",
    "                    value = float(lines[i+1])\n",
    "                    values['False Alarms'] = value\n",
    "                except ValueError:\n",
    "                    pass\n",
    "            \n",
    "            # Median Reaction Time\n",
    "            if 'Median Reaction Time' in line and i+1 < len(lines):\n",
    "                try:\n",
    "                    value = float(lines[i+1])\n",
    "                    values['Median Reaction Time'] = value\n",
    "                except ValueError:\n",
    "                    pass\n",
    "        \n",
    "        # Extract ERP values using the working approach\n",
    "        for i in range(len(lines) - 5):\n",
    "            # P50 Amplitude\n",
    "            if lines[i] == 'P50' and i+1 < len(lines) and lines[i+1] == 'Standard':\n",
    "                if i+2 < len(lines):\n",
    "                    try:\n",
    "                        values['P50 Amplitude'] = float(lines[i+2])\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "            \n",
    "            # P3b Amplitude and Latency\n",
    "            if lines[i] == 'P3b' and i+1 < len(lines) and lines[i+1] == 'Target':\n",
    "                if i+2 < len(lines) and i+3 < len(lines):\n",
    "                    try:\n",
    "                        values['P3b Amplitude'] = float(lines[i+2])\n",
    "                        values['P3b Latency'] = float(lines[i+3])\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "            \n",
    "            # Peak Alpha Frequency\n",
    "            if lines[i] == 'Peak Alpha' and i+1 < len(lines):\n",
    "                try:\n",
    "                    values['Peak Alpha Frequency'] = float(lines[i+1])\n",
    "                except ValueError:\n",
    "                    pass\n",
    "        \n",
    "        return values\n",
    "    \n",
    "    def extract_discussion_interpretations(self, discussion_text: str) -> Dict:\n",
    "        \"\"\"Extract interpretations from Study Discussion (if needed for comparison)\"\"\"\n",
    "        interpretations = {}\n",
    "        \n",
    "        patterns = {\n",
    "            'Button Press Accuracy': r'Button Press Accuracy[:\\s]*(Low|Normal|High)',\n",
    "            'Median Reaction Time': r'Median Reaction Time[:\\s]*(Delayed|Normal|Fast)',\n",
    "            'P50 Amplitude': r'P50 Amplitude[:\\s]*(Low|Normal|High)',\n",
    "            'P3b Amplitude': r'P3b Amplitude[:\\s]*(Low|Normal|High)',\n",
    "            'P3b Latency': r'P3b Latency[:\\s]*(Delayed|Normal|Fast)',\n",
    "            'Peak Alpha Frequency': r'Peak Alpha Frequency[:\\s]*(Low|Normal|High)'\n",
    "        }\n",
    "        \n",
    "        for metric, pattern in patterns.items():\n",
    "            match = re.search(pattern, discussion_text, re.IGNORECASE)\n",
    "            if match:\n",
    "                interpretations[metric] = match.group(1)\n",
    "        \n",
    "        return interpretations\n",
    "    \n",
    "    def calculate_interpretations(self, values: Dict) -> Dict:\n",
    "        \"\"\"Calculate interpretations based on normal ranges\"\"\"\n",
    "        interpretations = {}\n",
    "        \n",
    "        for metric, value in values.items():\n",
    "            if metric in self.normal_ranges:\n",
    "                range_info = self.normal_ranges[metric]\n",
    "                min_val = range_info['min']\n",
    "                max_val = range_info['max']\n",
    "                \n",
    "                if metric in ['Median Reaction Time', 'P3b Latency']:\n",
    "                    # For timing metrics, higher = delayed\n",
    "                    if value > max_val:\n",
    "                        interpretations[metric] = 'Delayed'\n",
    "                    elif value < min_val:\n",
    "                        interpretations[metric] = 'Fast'\n",
    "                    else:\n",
    "                        interpretations[metric] = 'Normal'\n",
    "                else:\n",
    "                    # For other metrics\n",
    "                    if value < min_val:\n",
    "                        interpretations[metric] = 'Low'\n",
    "                    elif value > max_val:\n",
    "                        interpretations[metric] = 'High'\n",
    "                    else:\n",
    "                        interpretations[metric] = 'Normal'\n",
    "        \n",
    "        return interpretations\n",
    "    \n",
    "    def process_pdf(self, pdf_path: str) -> Dict:\n",
    "        \"\"\"Main processing function\"\"\"\n",
    "        print(f\"Processing: {pdf_path}\")\n",
    "        \n",
    "        # Extract text\n",
    "        text = self.extract_pdf_text(pdf_path)\n",
    "        if not text:\n",
    "            return {\"error\": \"Could not extract text from PDF\"}\n",
    "        \n",
    "        # Extract values and calculate interpretations\n",
    "        values = self.extract_all_values(text)\n",
    "        calculated_interpretations = self.calculate_interpretations(values)\n",
    "        \n",
    "        # Generate our own study findings and discussion based on the data\n",
    "        generated_findings = self.generate_study_findings(values, calculated_interpretations)\n",
    "        generated_discussion = self.generate_study_discussion(values, calculated_interpretations)\n",
    "        \n",
    "        # Optional: Extract original interpretations for comparison (but don't use as primary)\n",
    "        original_discussion_text = \"\"\n",
    "        discussion_pattern = r'Study Discussion:?\\s*(.*?)(?=Study Protocol|Test Name|Physician|$)'\n",
    "        discussion_match = re.search(discussion_pattern, text, re.DOTALL | re.IGNORECASE)\n",
    "        if discussion_match:\n",
    "            original_discussion_text = discussion_match.group(1).strip()\n",
    "        \n",
    "        original_interpretations = self.extract_discussion_interpretations(original_discussion_text)\n",
    "        \n",
    "        return {\n",
    "            'generated_study_findings': generated_findings,\n",
    "            'generated_study_discussion': generated_discussion,\n",
    "            'extracted_values': values,\n",
    "            'our_interpretations': calculated_interpretations,\n",
    "            'original_interpretations': original_interpretations,  # For comparison only\n",
    "        }\n",
    "    \n",
    "    def print_results(self, results: Dict):\n",
    "        \"\"\"Print results in a clean format\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"                    MEDICAL REPORT ANALYSIS RESULTS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Generated Study Findings (our analysis)\n",
    "        if results.get('generated_study_findings'):\n",
    "            print(\"\\nðŸ“‹ GENERATED STUDY FINDINGS (Based on Data Analysis):\")\n",
    "            print(\"-\" * 60)\n",
    "            print(results['generated_study_findings'])\n",
    "        \n",
    "        # Generated Study Discussion (our analysis)\n",
    "        if results.get('generated_study_discussion'):\n",
    "            print(\"\\nðŸ’­ GENERATED STUDY DISCUSSION (Based on Data Analysis):\")\n",
    "            print(\"-\" * 60)\n",
    "            print(results['generated_study_discussion'])\n",
    "        \n",
    "        # Extracted Values\n",
    "        values = results.get('extracted_values', {})\n",
    "        if values:\n",
    "            print(\"\\nðŸ“Š EXTRACTED VALUES:\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            # Group by category\n",
    "            task_metrics = ['Button Press Accuracy', 'False Alarms', 'Median Reaction Time']\n",
    "            erp_metrics = ['P50 Amplitude', 'P3b Amplitude', 'P3b Latency']\n",
    "            eeg_metrics = ['Peak Alpha Frequency']\n",
    "            \n",
    "            def print_category(title, metrics):\n",
    "                category_values = {k: v for k, v in values.items() if k in metrics}\n",
    "                if category_values:\n",
    "                    print(f\"\\n  {title}:\")\n",
    "                    for metric, value in category_values.items():\n",
    "                        # Show value with interpretation\n",
    "                        interpretation = results.get('our_interpretations', {}).get(metric, 'Unknown')\n",
    "                        emoji = \"ðŸ”´\" if interpretation.lower() in ['low', 'delayed'] else \"ðŸŸ¢\" if interpretation.lower() == 'normal' else \"ðŸŸ¡\"\n",
    "                        print(f\"    {emoji} {metric:<25}: {value} ({interpretation})\")\n",
    "            \n",
    "            print_category(\"Task Performance\", task_metrics)\n",
    "            print_category(\"ERP Features\", erp_metrics)\n",
    "            print_category(\"EEG Features\", eeg_metrics)\n",
    "        \n",
    "        # Our Interpretations\n",
    "        our_interp = results.get('our_interpretations', {})\n",
    "        if our_interp:\n",
    "            print(\"\\nðŸ§® OUR INTERPRETATIONS (Based on Normal Ranges):\")\n",
    "            print(\"-\" * 55)\n",
    "            for metric, interpretation in our_interp.items():\n",
    "                emoji = \"ðŸ”´\" if interpretation.lower() in ['low', 'delayed'] else \"ðŸŸ¢\" if interpretation.lower() == 'normal' else \"ðŸŸ¡\"\n",
    "                print(f\"  {emoji} {metric:<25}: {interpretation}\")\n",
    "        \n",
    "        # Original interpretations (for comparison only)\n",
    "        original_interp = results.get('original_interpretations', {})\n",
    "        if original_interp:\n",
    "            print(\"\\nðŸ“„ ORIGINAL REPORT INTERPRETATIONS (For Comparison):\")\n",
    "            print(\"-\" * 55)\n",
    "            for metric, interpretation in original_interp.items():\n",
    "                emoji = \"ðŸ”´\" if interpretation.lower() in ['low', 'delayed'] else \"ðŸŸ¢\" if interpretation.lower() == 'normal' else \"ðŸŸ¡\"\n",
    "                print(f\"  {emoji} {metric:<25}: {interpretation}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "    def save_to_csv(self, results: Dict, output_file: str = 'medical_report_analysis.csv'):\n",
    "        \"\"\"Save results to CSV\"\"\"\n",
    "        data = []\n",
    "        \n",
    "        values = results.get('extracted_values', {})\n",
    "        our_interp = results.get('our_interpretations', {})\n",
    "        original_interp = results.get('original_interpretations', {})\n",
    "        \n",
    "        all_metrics = set(values.keys()) | set(our_interp.keys()) | set(original_interp.keys())\n",
    "        \n",
    "        for metric in sorted(all_metrics):\n",
    "            data.append({\n",
    "                'Metric': metric,\n",
    "                'Value': values.get(metric, 'Not found'),\n",
    "                'Our_Interpretation': our_interp.get(metric, 'Not found'),\n",
    "                'Original_Interpretation': original_interp.get(metric, 'Not found'),\n",
    "                'Match': 'Yes' if our_interp.get(metric) == original_interp.get(metric) else 'No'\n",
    "            })\n",
    "        \n",
    "        if results.get('generated_study_findings'):\n",
    "            data.append({\n",
    "                'Metric': 'GENERATED_STUDY_FINDINGS',\n",
    "                'Value': results['generated_study_findings'],\n",
    "                'Our_Interpretation': 'Generated from data',\n",
    "                'Original_Interpretation': 'N/A',\n",
    "                'Match': 'N/A'\n",
    "            })\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"ðŸ’¾ Results saved to {output_file}\")\n",
    "\n",
    "\n",
    "# Usage examples\n",
    "def process_single_pdf(pdf_path: str):\n",
    "    \"\"\"Process a single PDF file\"\"\"\n",
    "    extractor = SimpleMedicalExtractor()\n",
    "    \n",
    "    try:\n",
    "        results = extractor.process_pdf(pdf_path)\n",
    "        extractor.print_results(results)\n",
    "        extractor.save_to_csv(results)\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pdf_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_multiple_pdfs(pdf_paths: list):\n",
    "    \"\"\"Process multiple PDF files\"\"\"\n",
    "    extractor = SimpleMedicalExtractor()\n",
    "    all_results = {}\n",
    "    \n",
    "    for pdf_path in pdf_paths:\n",
    "        try:\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Processing: {pdf_path}\")\n",
    "            print('='*60)\n",
    "            \n",
    "            results = extractor.process_pdf(pdf_path)\n",
    "            extractor.print_results(results)\n",
    "            \n",
    "            # Save individual CSV\n",
    "            csv_name = pdf_path.replace('.pdf', '_summary.csv')\n",
    "            extractor.save_to_csv(results, csv_name)\n",
    "            \n",
    "            all_results[pdf_path] = results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {pdf_path}: {e}\")\n",
    "            all_results[pdf_path] = {\"error\": str(e)}\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Process single PDF\n",
    "    pdf_file = \"Patient_30627.pdf\"  # Replace with your PDF path\n",
    "    \n",
    "    print(\"ðŸ”¬ Medical PDF Extractor - Simplified Version\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    results = process_single_pdf(pdf_file)\n",
    "    \n",
    "    # Uncomment below to process multiple PDFs\n",
    "    # pdf_files = [\"Patient_30627.pdf\", \"Patient_12345.pdf\", \"Patient_67890.pdf\"]\n",
    "    # all_results = process_multiple_pdfs(pdf_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
